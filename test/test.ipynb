{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "378f0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from credmodex.credlab import CredLab\n",
    "import credmodex\n",
    "from graphmodex import plotlymodex\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from credmodex.utils import plotly_main_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77435452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_structure(root_dir):\n",
    "    structure = []\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        # Modify dirs in-place to skip __pycache__\n",
    "        dirs[:] = [d for d in dirs \n",
    "                   if (d != '__pycache__')]\n",
    "\n",
    "        level = root.replace(root_dir, '').count(os.sep)\n",
    "        indent = ' ' * 4 * level\n",
    "        structure.append(f'{indent}{os.path.basename(root)}/')\n",
    "\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            structure.append(f'{subindent}{f}')\n",
    "    return '\\n'.join(structure)\n",
    "\n",
    "# print(get_structure(r'C:\\Users\\gustavo.filho\\Documents\\Python\\Modules\\Credit Risk\\credmodex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d517fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = {\n",
    "#     \"rating\": list(range(1, 10)),\n",
    "#     \"target\": [1, 0, 1, 1, 1, 0, 1, 0, 1,],\n",
    "#     \"score\": [0.90, 0.10, 0.80, 0.70, 0.45, 0.35, 0.70, 0.20, 0.80],\n",
    "# }\n",
    "# df = pd.DataFrame(df)\n",
    "\n",
    "# df = {\n",
    "#     'rating': [0]*(95+309) + [1]*(187+224) + [2]*(549+299) + [3]*(1409+495) + [4]*(3743+690) + [5]*(4390+424) + [6]*(2008+94) + [7]*(593+8),\n",
    "#     'target': [0]*95+[1]*309 + [0]*187+[1]*224 + [0]*549+[1]*299 + [0]*1409+[1]*495 + [0]*3743+[1]*690 + [0]*4390+[1]*424 + [0]*2008+[1]*94 + [0]*593+[1]*8,\n",
    "#     'score': [309/(95+309)]*(95+309) + [224/(187+224)]*(187+224) + [299/(549+299)]*(549+299) + [495/(1409+495)]*(1409+495) + [690/(3743+690)]*(3743+690) + [424/(4390+424)]*(4390+424) + [94/(2008+94)]*(2008+94) + [8/(593+8)]*(593+8)\n",
    "# }\n",
    "# df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faa51e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_rows = 10000\n",
    "n_cols = 20\n",
    "\n",
    "dates = pd.date_range(start=\"2025-01-01\", end=\"2025-05-30\", periods=n_rows)\n",
    "\n",
    "data = {\"date\": dates}\n",
    "\n",
    "for i in range(3):\n",
    "    data[f\"cat_30_{i}\"] = np.random.choice([f\"{j}\" for j in range(30)], size=n_rows)\n",
    "for i in range(2):\n",
    "    data[f\"cat_5_{i}\"] = np.random.choice([f\"{j}\" for j in ['a','b','c','d','e']], size=n_rows)\n",
    "\n",
    "# Generate 5 integer columns (ordered, like credit history length, loan duration)\n",
    "for i in range(5):\n",
    "    data[f\"int_{i}\"] = np.random.randint(0, 100, size=n_rows)\n",
    "\n",
    "# Generate 5 float columns (e.g. income, loan amount, utilization)\n",
    "for i in range(5):\n",
    "    data[f\"float_{i}\"] = np.random.normal(loc=5000, scale=2000, size=n_rows)\n",
    "\n",
    "# Generate 2 columns with mostly missing values\n",
    "data[\"mostly_nan_1\"] = np.where(np.random.rand(n_rows) < 0.95, np.nan, np.random.rand(n_rows))\n",
    "data[\"mostly_nan_2\"] = np.where(np.random.rand(n_rows) < 0.9, np.nan, np.random.rand(n_rows))\n",
    "\n",
    "# Generate 1 column with some special missing values (inf, -inf)\n",
    "special_col = np.random.normal(loc=100, scale=50, size=n_rows)\n",
    "special_col[np.random.choice(n_rows, size=10, replace=False)] = np.inf\n",
    "special_col[np.random.choice(n_rows, size=10, replace=False)] = -np.inf\n",
    "special_col[np.random.choice(n_rows, size=100, replace=False)] = np.nan\n",
    "data[\"special_missing\"] = special_col\n",
    "\n",
    "# Fixing the target column to handle NaNs by using float type\n",
    "target = np.random.choice([0, 1], size=n_rows).astype(float)\n",
    "mask = np.random.rand(n_rows) < 0.2\n",
    "target[mask] = np.nan\n",
    "data[\"target\"] = target\n",
    "\n",
    "for i, col in enumerate([col for col in data if col.startswith(\"cat_\")]):\n",
    "    if (i == 3) or (i == 1): continue\n",
    "    nan_indices = np.random.choice(n_rows, size=50, replace=False)\n",
    "    temp_col = np.array(data[col], dtype=object)\n",
    "    temp_col[nan_indices] = np.nan\n",
    "    data[col] = temp_col\n",
    "\n",
    "# Insert a few NaNs into the float columns\n",
    "for i, col in enumerate([col for col in data if col.startswith(\"float_\")]):\n",
    "    if (i == 3): break\n",
    "    nan_indices = np.random.choice(n_rows, size=30, replace=False)\n",
    "    temp_col = data[col]\n",
    "    temp_col[nan_indices] = np.nan\n",
    "    data[col] = temp_col\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
